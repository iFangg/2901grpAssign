%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Lachaise Assignment
% LaTeX Template
% Version 1.0 (26/6/2018)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Marion Lachaise & François Févotte
% Vel (vel@LaTeXTemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{parskip}
\usepackage{amsmath}
\usepackage{amsthm}

\DeclareMathOperator{\Ima}{im}

\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{Math2901: Group Assignment} % Title of the assignment

\author{Dylan Wang, Ivan Fang\\ \texttt{z5422214@ad.unsw.edu.au, z5418045@ad.unsw.edu.au}} % Author name and email address

\date{University of New South Wales --- \today} % University, school and/or department name(s) and a date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\section*{Question 1 Solutions} % Unnumbered section
Let $A, B\subseteq\Omega$.

1. 

Given that event $A$ is independent of itself, this means that $\mathbb{P}(A|A) = \mathbb{P}(A)$. This implies $\mathbb{P}(A) = \mathbb{P}(A)$ and so $\mathbb{P}(A)$ must equal either $1$ or $0$.

2.

Given event $A$ such that $\mathbb{P}(A) = 1$ or $\mathbb{P}(A) = 0$, we observe the conditional probability between events $A$ and $B$.

For the case where $\mathbb{P}(A) = 1$:
\begin{align*}
    \mathbb{P}(B|A) &= \frac{\mathbb{P}(B\cap A)}{\mathbb{P}(A)}\\
    &= \mathbb{P}(B\cap A)\\
    &= \mathbb{P}(B)\mbox{.}
\end{align*}
\hspace*{6mm}We reach this result because the intersection with a guaranteed event will always be the probability of the other event.

For the case where $\mathbb{P}(A) = 0$:
\begin{align*}
    \mathbb{P}(A|B) &= \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}\\
    &= \frac{\mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A\cup B)}{\mathbb{P}(B)}\\
    &= \frac{\mathbb{P}(B) - \mathbb{P}(A\cup B)}{\mathbb{P}(B)}\\
    &= \frac{\mathbb{P}(B) - \mathbb{P}(B)}{\mathbb{P}(B)}\\
    % &= \frac{0}{\mathbb{P}(B)}\\
    &= 0\\
    &= \mathbb{P}(A)\mbox{.}
\end{align*}
\hspace*{6mm} Since the union with an impossible event always returns the probability of the other event, we reach our result.

3.

Note, by the Total Law of Probability, $\mathbb{P}(A\cap B) \leq 0$.

Now observe,
\begin{align*}
    \mathbb{P}(A\cap B) & = \mathbb{P}(A) +\mathbb{P}(B) - \mathbb{P}(A\cap B)\\    
    1 &\geq \mathbb{P}(A) +\mathbb{P}(B) - \mathbb{P}(A\cap B)\\
    \mathbb{P}(A\cap B)\ &\geq \mathbb{P}(A) +\mathbb{P}(B) - 1\mbox{.}
\end{align*}
\hspace*{6mm} The inequality has been proven, thus we are done.

4.

Using the previous proven inequality,
\begin{align*}
    \mathbb{P}(A_1\cap A_2)\ &\geq \mathbb{P}(A_1) + \mathbb{P}(A_2) - 1\\
    \mathbb{P}(A_1\cap A_2\cap A_3)\ &\geq \mathbb{P}(A_1) + \mathbb{P}(A_2) - 1\\
    &= \mathbb{P}(A_1) +\mathbb{P}(A_2) - 1 +  \mathbb{P}(A_3) - 1\\
    &= \mathbb{P}(A_1) +\mathbb{P}(A_2) +  \mathbb{P}(A_3) - 2\\
    &\vdots\\
    \mathbb{P}(\bigcap_{i = 1}^n A_i)\ &\geq \sum_{i = 1}^{n} A_i - (n-1)\mbox{.}
\end{align*}
\hspace*{6mm} We have thus proved the inequality. 

\section*{Question 2 Solutions} % Unnumbered section


\section*{Question 3 Solutions} % Unnumbered section
1.

We can see that $\tilde{X_n} = \bar{X_n} + \frac{1}{n}(2X_1)-\frac{1}{n}\left(X_{n-1}+X_n\right)$. Now calculating the bias of $\tilde{X_n}$
\begin{align*}
    \mbox{Bias}(\tilde{X_n}) &=\mbox{E}(\tilde{X_n})-\mu\\
    &= \frac{1}{n}\mbox{E}\left(\sum_{i = 1}^{n}X_i + 2X_1 - (X_{n-1}+X_n)\right)-\mu\\
    &= \frac{1}{n}\mbox{E}\left(\sum_{i = 1}^{n}X_i\right)+\frac{1}{n}\mbox{E}(2X_1)-\frac{1}{n}\mbox{E}(X_{n-1}+X_n)\mu\mbox{.}
\end{align*}
\hspace*{6mm}Because the random sample is independent identiclaly distributed, the expected value of each variable in the sample is equal to the mean. This means that our simplified equation becomes
\begin{align*}
    \frac{1}{n}\mbox{E}\left(\sum_{i = 1}^{n}X_i\right)+\frac{2}{n}\mbox{E}(X_1)-\frac{1}{n}\mbox{E}(X_{n-1})-\frac{1}{n}\mbox{E}(X_n)\mu &= \mu + \frac{2}{n}\mu -\frac{1}{n}\mu -\frac{1}{n}\mu -\mu\\
    &= 0\mbox{.}
\end{align*}
We have thus shown that $\tilde{X_n}$ is an unbiased estimator of $\mu$.

2.

The mean square error can be written as
\begin{align*}
    \mbox{MSE}(\tilde{X_n}) &= \mbox{Var}(\tilde{X_n})+(\mbox{Bias}(\tilde{X_n}))^2\\
    &= \mbox{Var}(\tilde{X_n})\\
    &= \mbox{E}(\tilde{X_n}^2)-\mbox{E}(\tilde{X_n})^2\\
    &= \mbox{E}\left[\frac{1}{n^2}\left(\sum_{i = 1}^{n}X_i + 2X_1-X_{n-1}-X_n\right)^2\right] - \mu^2\\
    &= \frac{1}{n^2}\mbox{E}\left[\left(\sum_{i = 1}^{n}X_i\right)^2 + 2\left(\sum_{i = 1}^{n}\right)(2X_1 - X_{n - 1} - X_n) + (2X_1 - X_{n - 1} - X_n)^2\right] - \mu^2\\
    &= \frac{1}{n^2}\mbox{E}\left[\left(\sum_{i = 1}^{n}X_i\right)^2\right] + \frac{2}{n^2}\mbox{E}\left[\left(\sum_{i = 1}^{n}X_i\right)(2X_1-X_{n-1}-X_n)\right]+\frac{1}{n^2}\mbox{E}\left[(2X_1-X_{n-1}-X_n)^2\right] - \mu^2\\
    &= \frac{1}{n}\mbox{E}\left(\sum_{i = 1}^{n}X_i\right)\times\frac{1}{n}\mbox{E}\left(\sum_{i = 1}^{n}X_i\right)+\frac{2}{n}\mbox{E}\left(\sum_{i = 1}^{n}X_i\right)\times\frac{1}{n}\mbox{E}(2X_1-X_{n-1}-X_n) + \frac{1}{n}\mbox{E}(2X_1-X_{n-1}-X_n)\times\frac{1}{n}\mbox{E}(2X_1-X_{n-1}-X_n) - \mu^2\\
    &= \mu^2 + 2\mu\times\frac{1}{n} + \left[\frac{1}{n}\mbox{E}(2X_1-X_{n-1}-X_n)\right]^2 - \mu^2\\
    &= 2\mu\times\frac{1}{n}(2\mu-\mu-\mu)+\frac{1}{n^2}(2\mu-\mu-\mu)^2\\
    &= 0\mbox{.}
\end{align*}
Thus, the MSE is $0$.

3.
\begin{align*}
    \lim_{n\rightarrow\infty}\mbox{MSE}(\tilde{X_n}) &= \lim_{n\rightarrow\infty}0\\
    &= 0\mbox{.}
\end{align*}

4.

Measure consistency of both estimators.

\section*{Question 4 Solutions} % Unnumbered section



\end{document}
